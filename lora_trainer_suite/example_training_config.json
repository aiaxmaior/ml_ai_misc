{
  "_comment": "Example config for Flux (images) - For WAN I2V video: use Wan-AI/Wan2.1-I2V-14B-720P or Wan-AI/Wan2.2-I2V-A14B",
  "base_model": "black-forest-labs/FLUX.1-dev",
  "output_name": "my_character_lora",
  "output_dir": "./output/loras",
  "dataset_path": "./datasets/my_character",
  "batch_size": 1,
  "gradient_accumulation_steps": 4,
  "learning_rate": 0.0001,
  "max_train_steps": 1000,
  "lora_rank": 16,
  "lora_alpha": 32,
  "optimizer": "AdamW8bit",
  "mixed_precision": "bf16",
  "gradient_checkpointing": true,
  "save_every_n_steps": 100,
  "sample_every_n_steps": 100,
  "sample_prompt": "a photo of sks person",
  "resolution": 512,
  "enable_xformers": true,
  "seed": 42,
  "notes": "Character LoRA training with recommended settings for RTX 3090. For WAN I2V video: use Wan-AI/Wan2.1-I2V-14B-720P or Wan-AI/Wan2.2-I2V-A14B (Qwen's Image-to-Video models). Workflow: Flux generates image â†’ WAN I2V animates it"
}
